{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c37c4f1-af33-4c9d-ad59-b2f14adb60b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"multiline\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .option(\"delimenter\", \",\")\\\n",
    "    .option(\"quote\",\"\\\"\")\\\n",
    "    .load(\"s3://cmg-databricks-lakehouse/mfd/practitioners/\")\n",
    "\n",
    "df = df.dropDuplicates([\"nookalDbID\", \"ID\"])\n",
    "\n",
    "# # Add an integer primary key. --- I think we should not do this because it will come up with different id everytime the data chanages and \n",
    "# when we run it, so rather I think we should use auto incrementing id while creating the table, in a separate sql\n",
    "# for now I have just left it like this to move faster\n",
    "# df_with_id = df.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "# Create a new table with the primary key\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"teamb.nk_rawPractitioners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4d7d96-11ec-469c-81a9-92793259ab6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df469284-331a-4e23-a2cf-23aaef941d1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--drop table teamb.nk_rawpractitioners"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7060014632111305,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "nk_rawPractitioners",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
