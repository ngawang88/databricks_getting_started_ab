{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c551759-1d45-4070-9b33-9bb4a84da7ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_appointment = spark.read.table(\"workspace.teamb.raw_appointments\")\n",
    "display(raw_appointment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a87f347f-7e4b-43aa-9308-4f77f6ecfd3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "\n",
    "raw_appointment = raw_appointment \\\n",
    "    .withColumn(\"cmgID\", expr(\"try_cast(cmgID as int)\")) \\\n",
    "    .withColumn(\"nookalDbID\", expr(\"try_cast(nookalDbID as string)\")) \\\n",
    "    .withColumn(\"ID\", expr(\"try_cast(ID as int)\")) \\\n",
    "    .withColumn(\"patientID\", expr(\"try_cast(patientID as int)\")) \\\n",
    "    .withColumn(\"date\", expr(\"try_cast(date as date)\")) \\\n",
    "    .withColumn(\"startTime\", expr(\"try_cast(startTime as timestamp)\")) \\\n",
    "    .withColumn(\"endTime\", expr(\"try_cast(endTime as timestamp)\")) \\\n",
    "    .withColumn(\"locationID\", expr(\"try_cast(locationID as int)\")) \\\n",
    "    .withColumn(\"type\", expr(\"try_cast(type as string)\")) \\\n",
    "    .withColumn(\"typeID\", expr(\"try_cast(typeID as int)\")) \\\n",
    "    .withColumn(\"practitionerID\", expr(\"try_cast(practitionerID as int)\")) \\\n",
    "    .withColumn(\"emailReminderSent\", expr(\"try_cast(emailReminderSent as boolean)\")) \\\n",
    "    .withColumn(\"arrived\", expr(\"try_cast(arrived as boolean)\")) \\\n",
    "    .withColumn(\"DNA\", expr(\"try_cast(DNA as boolean)\")) \\\n",
    "    .withColumn(\"cancelled\", expr(\"try_cast(cancelled as boolean)\")) \\\n",
    "    .withColumn(\"cancellationDate\", expr(\"try_cast(cancellationDate as date)\")) \\\n",
    "    .withColumn(\"notes\", expr(\"try_cast(notes as string)\")) \\\n",
    "    .withColumn(\"dateModified\", expr(\"try_cast(dateModified as date)\")) \\\n",
    "    .withColumn(\"dateCreated\", expr(\"try_cast(dateCreated as date)\")) \\\n",
    "    .withColumn(\"invoiceGenerated\", expr(\"try_cast(invoiceGenerated as boolean)\")) \\\n",
    "    .withColumn(\"source_name\", expr(\"try_cast(source_name as string)\")) \\\n",
    "    .withColumn(\"source_row_count\", expr(\"try_cast(source_row_count as int)\")) \\\n",
    "    .withColumn(\"dtmCreated\", expr(\"try_cast(dtmCreated as timestamp)\")) \\\n",
    "    .withColumn(\"dtmUpdated\", expr(\"try_cast(dtmUpdated as timestamp)\")) \\\n",
    "    .withColumn(\"dtmProcessed\", expr(\"try_cast(dtmProcessed as timestamp)\"))\n",
    "\n",
    "\n",
    "raw_appointment.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ecf745-431c-424f-8ff0-36bb0d77a8fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#drop rows that contains null values in cmgID and ID\n",
    "raw_appointment = raw_appointment.dropna(subset=[\"cmgID\", \"ID\"])\n",
    "\n",
    "#Drop duplicates\n",
    "raw_appointment = raw_appointment.dropDuplicates([\"nookalDbID\",\"ID\",\"patientID\"])\n",
    "raw_appointment.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8feb4add-68e1-4f64-bf3a-ad6cebe36e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# this is something that I want to do so that we can flag invalid datatype value  rether than nulling it out \n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0\n",
    "\n",
    "# from pyspark.sql.functions import col\n",
    "# import sys\n",
    "# sys.path.append(\"/Workspace/Shared/databricks_getting_started_ab/prod/files/src\")\n",
    "\n",
    "# from udf.datatype_utils import *\n",
    "\n",
    "\n",
    "# # Define the column -> UDF mapping\n",
    "# column_validators = {\n",
    "#     \"cmgID\": isIntUDF,\n",
    "#     \"nookalDbID\": isIntUDF,\n",
    "#     \"ID\": isIntUDF,\n",
    "#     \"patientID\": isIntUDF,\n",
    "#     \"date\": isDateUDF,\n",
    "#     \"startTime\": isTimestampUDF,\n",
    "#     \"endTime\": isTimestampUDF,\n",
    "#     \"locationID\": isIntUDF,\n",
    "#     \"type\": isIntUDF,\n",
    "#     \"typeID\": isIntUDF,\n",
    "#     \"practitionerID\": isIntUDF,\n",
    "#     \"emailReminderSent\": isBoolUDF,\n",
    "#     \"arrived\": isBoolUDF,\n",
    "#     \"DNA\": isBoolUDF,\n",
    "#     \"cancelled\": isBoolUDF,\n",
    "#     \"cancellationDate\": isDateUDF,\n",
    "#     \"dateModified\": isDateUDF,\n",
    "#     \"dateCreated\": isDateUDF,\n",
    "#     \"invoiceGenerated\": isBoolUDF,\n",
    "#     \"source_row_count\": isIntUDF,\n",
    "#     \"dtmCreated\": isTimestampUDF,\n",
    "#     \"dtmUpdated\": isTimestampUDF,\n",
    "#     \"dtmProcessed\": isTimestampUDF\n",
    "# }\n",
    "\n",
    "# # Apply filter for all columns with validators\n",
    "# for col_name, validator in column_validators.items():\n",
    "#     if validator is not None:\n",
    "#         raw_appointment = raw_appointment.filter(validator(col(col_name)))\n",
    "# raw_appointment.display()\n",
    "\n",
    "# #Mapping of column name to final desired data type\n",
    "# cast_map = {\n",
    "#     \"cmgID\": \"int\",\n",
    "#     \"nookalDbID\": \"string\",  \n",
    "#     \"ID\": \"int\",\n",
    "#     \"patientID\": \"int\",\n",
    "#     \"date\": \"date\",\n",
    "#     \"startTime\": \"timestamp\",\n",
    "#     \"endTime\": \"timestamp\",\n",
    "#     \"locationID\": \"int\",\n",
    "#     \"type\": \"int\",\n",
    "#     \"typeID\": \"int\",\n",
    "#     \"practitionerID\": \"int\",\n",
    "#     \"emailReminderSent\": \"boolean\",\n",
    "#     \"arrived\": \"boolean\",\n",
    "#     \"DNA\": \"boolean\",\n",
    "#     \"cancelled\": \"boolean\",\n",
    "#     \"cancellationDate\": \"date\",\n",
    "#     \"dateModified\": \"date\",\n",
    "#     \"dateCreated\": \"date\",\n",
    "#     \"invoiceGenerated\": \"boolean\",\n",
    "#     \"source_row_count\": \"int\",\n",
    "#     \"dtmCreated\": \"timestamp\",\n",
    "#     \"dtmUpdated\": \"timestamp\",\n",
    "#     \"dtmProcessed\": \"timestamp\"\n",
    "#     # notes and source_name left uncasted (assumed string or free text)\n",
    "# }\n",
    "\n",
    "# # Apply casting to all specified columns\n",
    "# for col_name, data_type in cast_map.items():\n",
    "#     raw_appointment = raw_appointment.withColumn(col_name, col(col_name).cast(data_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02273eb5-1f94-4f90-89f8-7c93d04465e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, lit\n",
    "\n",
    "# Select the columns that we need in cdm and add appointmentID and sourceCmgID\n",
    "cdm_appointment = raw_appointment.select(\n",
    "    col(\"cmgID\").alias(\"sourceCmgID\"),\n",
    "    \"nookalDbID\",\n",
    "    \"ID\",\n",
    "    \"patientID\",\n",
    "    \"date\",\n",
    "    \"startTime\",\n",
    "    \"endTime\",\n",
    "    \"locationID\",\n",
    "    \"type\",\n",
    "    \"typeID\",\n",
    "    \"practitionerID\",\n",
    "    \"emailReminderSent\",\n",
    "    \"arrived\",\n",
    "    \"DNA\",\n",
    "    \"cancelled\",\n",
    "    \"cancellationDate\",\n",
    "    \"notes\",\n",
    "    \"dateModified\",\n",
    "    \"dateCreated\",\n",
    "    \"invoiceGenerated\",\n",
    "    col(\"dtmCreated\").alias(\"dtmCreatedSource\"),\n",
    "    col(\"dtmUpdated\").alias(\"dtmUpdatedSource\"),\n",
    "    col(\"dtmProcessed\").alias(\"dtmProcessedSource\"),\n",
    "    current_timestamp().alias(\"dtmCreated\")\n",
    ")\n",
    "display(cdm_appointment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d9cc0ad-6f7b-4021-a218-04578c3b3f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "table_name = \"teamb.cdm_appointment\"\n",
    "\n",
    "insert_cols = cdm_appointment.columns  # excludes appointmentID since it's not present\n",
    "insert_map = {col: f\"source.{col}\" for col in insert_cols}\n",
    "\n",
    "try:\n",
    "    cdm_table = DeltaTable.forName(spark, table_name)\n",
    "\n",
    "    (\n",
    "        cdm_table.alias(\"target\")\n",
    "        .merge(\n",
    "            cdm_appointment.alias(\"source\"),\n",
    "            \"target.sourceCmgID = source.sourceCmgID\"\n",
    "        )\n",
    "        .whenMatchedUpdate(set=insert_map)\n",
    "        .whenNotMatchedInsert(values=insert_map) \n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    print(\"Merge completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the merge operation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3eb0987-a32a-4b52-b70d-0e4bea717214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM teamb.cdm_appointment\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5903650619095195,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "patients",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
